# Day 3 : conditional PRobability

- Conditional probability is an important concept
in statistics because often we are trying to establish that a factor has a relationship with an outcome.
- A factor has a relationship with an outcome when the probability of the outcomes differs depending on the presence or absence of the factor. This is expressed symbolically as P(E|F) and read as “the probability of
E given F.
- Conditional probabilities can also be used to define independence. Two variables are said to be independent if the following relationship holds: 
P(E|F) = P(E)
- Bayes’ theorem is one of the most common applications of conditional probabilities. Bayes' theorem is the law of probability governing the strength of evidence - the rule saying how much to revise our probabilities when we learn a new fact or observe new evidence.
- “Rationality is not about knowing facts, it’s about recognizing which facts are relevant.”
- "Evidence should not determine beliefs, but update them."


Reference:

1. Bayes theorem. Perhaps the most important formula in probability. https://t.co/JJ6xyVuSph?amp=1
2. The Arbital Guide to Bayes’s Rule https://t.co/PdVmoho4YD?amp=1